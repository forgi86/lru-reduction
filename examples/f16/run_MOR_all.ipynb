{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "import numpy as np\n",
    "from lru.architectures import DLRU, DLRUConfig\n",
    "from lru.reduction import lru_reduction_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchid.metrics  # pip install pytorch-ident\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_folder = (\"F16GVT_Files\", \"BenchmarkData\")\n",
    "file_name = \"F16Data_FullMSine_Level6_Validation.mat\"\n",
    "file_path = Path(*data_folder) / file_name\n",
    "data = scipy.io.loadmat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = data[\"Force\"].T  # Or force\n",
    "y_test = data[\"Acceleration\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS = [\"ckpt_large_no_reg\", \"ckpt_large_reg_modal\", \"ckpt_large_reg_hankel\"]\n",
    "REDUCTIONS = [\"balanced_truncation\", \"balanced_singular_perturbation\", \"modal_truncation\", \"modal_singular_perturbation\"]\n",
    "FIT_THRESHOLD = 83.25865396027804*0.99 # 1% less than the worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_state = 100\n",
    "MODES = np.arange(d_state, 0, -1) # all modes to be tested\n",
    "FIT_MEAN_ALL = np.empty((len(RUNS), len(REDUCTIONS), d_state))\n",
    "MIN_ORDER_ALL = np.empty((len(RUNS), len(REDUCTIONS)), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_run, run in enumerate(RUNS): # different regularizers applied\n",
    "    ckpt = torch.load(Path(\"ckpt\")/ f\"{run}.pt\", map_location=\"cpu\")\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "    scaler_u = ckpt[\"scaler_u\"]\n",
    "    scaler_y = ckpt[\"scaler_y\"]\n",
    "\n",
    "    # Load model\n",
    "    config = DLRUConfig(\n",
    "        d_model=cfg.d_model, d_state=cfg.d_state, n_layers=cfg.n_layers, ff=cfg.ff\n",
    "    )\n",
    "    assert(cfg.d_state == d_state)\n",
    "    model = DLRUConfig(1, 3, config)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "\n",
    "    for idx_red, reduction_method in enumerate(REDUCTIONS): # different reductions applied\n",
    "        print(f\"{run} {reduction_method}\")\n",
    "\n",
    "        FIT_MEAN = []\n",
    "        for modes in MODES:\n",
    "            model_reduced = copy.deepcopy(model)\n",
    "            for block in model_reduced.blocks:\n",
    "\n",
    "                # reduction pipeline\n",
    "                ss_params = block.lru.ss_params()\n",
    "                ss_params = [param.detach().numpy() for param in ss_params]\n",
    "                lambdas, B, C, D = ss_params\n",
    "                lambdas_red, B_red, C_red, D_red = lru_reduction_pipeline(lambdas, B, C, D,  modes=modes, method=reduction_method)\n",
    "\n",
    "\n",
    "                params_red = [lambdas_red.astype(np.complex64), B_red.astype(np.complex64), C_red.astype(np.complex64), D_red.astype(np.float32)]\n",
    "                params_red = [torch.tensor(param_red) for param_red in params_red]\n",
    "                block.lru.replace_ss_params(*params_red)\n",
    "\n",
    "            ut = torch.tensor(scaler_u.transform(u_test)).unsqueeze(0).float()\n",
    "            with torch.no_grad():\n",
    "                #    y_test_hat = model(ut, mode=\"scan\").squeeze(0).to(\"cpu\").numpy()\n",
    "                y_test_hat = model_reduced(ut, mode=\"scan\").squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "            y_test_hat = scaler_y.inverse_transform(y_test_hat)\n",
    "\n",
    "            fit = torchid.metrics.fit_index(y_test, y_test_hat).mean()\n",
    "            FIT_MEAN.append(fit)\n",
    "\n",
    "        FIT_MEAN = np.array(FIT_MEAN)\n",
    "        MIN_ORDER_ALL[idx_run, idx_red] = MODES[FIT_MEAN > FIT_THRESHOLD].min()\n",
    "        FIT_MEAN_ALL[idx_run, idx_red, :cfg.d_state] = FIT_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_ORDER_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "fit_mean_all = xarray.DataArray(FIT_MEAN_ALL,\n",
    "                 dims=[\"run\", \"truncation_method\", \"modes\"],\n",
    "                 coords=[RUNS, REDUCTIONS, MODES])\n",
    "fit_mean_all.to_netcdf(\"fit_mean_all.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_mean_all[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(MODES, fit_mean_all.loc[\"ckpt_large_no_reg\", \"balanced_truncation\"])\n",
    "ax.axhline(FIT_THRESHOLD, color=\"red\")\n",
    "ax.invert_xaxis()\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Number of retained modes (-)\")\n",
    "ax.set_ylabel(\"Average FIT (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
