{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "import numpy as np\n",
    "from lru.architectures import DLRU, DLRUConfig\n",
    "from lru.reduction import lru_reduction_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchid.metrics  # pip install pytorch-ident\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_folder = (\"F16GVT_Files\", \"BenchmarkData\")\n",
    "\n",
    "# file_name = \"F16Data_SineSw_Level5.mat\"\n",
    "#\n",
    "# file_name = \"F16Data_FullMSine_Level7.mat\"\n",
    "# file_name = \"F16Data_FullMSine_Level5.mat\"\n",
    "# file_name = \"F16Data_FullMSine_Level4_Validation.mat\"\n",
    "file_name = \"F16Data_FullMSine_Level6_Validation.mat\"\n",
    "# file_name = \"F16Data_SineSw_Level6_Validation.mat\"\n",
    "file_path = Path(*data_folder) / file_name\n",
    "data = scipy.io.loadmat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"ckpt_large_reg_hankel\"\n",
    "#run = \"ckpt_large_reg_hankel_cc\"\n",
    "#run = \"ckpt_large_reg_modal\"  # lasso on eigs abs val\n",
    "#run = \"ckpt_large_no_reg\"\n",
    "# run = \"ckpt_large_no_reg_last\"\n",
    "# run = \"ckpt_small_no_reg\"\n",
    "# run = \"ckpt_small_reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduction_method = \"balanced_truncation\"\n",
    "#reduction_method = \"balanced_singular_perturbation\"\n",
    "reduction_method = \"modal_truncation\"\n",
    "#reduction_method = \"modal_singular_perturbation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco.forgione/anaconda3/envs/dev/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.4.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(Path(\"ckpt\")/ f\"{run}.pt\", map_location=\"cpu\")\n",
    "cfg = ckpt[\"cfg\"]\n",
    "scaler_u = ckpt[\"scaler_u\"]\n",
    "scaler_y = ckpt[\"scaler_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = data[\"Force\"].T  # Or force\n",
    "y_test = data[\"Acceleration\"].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DLRUConfig' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m DLRUConfig(\n\u001b[1;32m      3\u001b[0m     d_model\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39md_model, d_state\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39md_state, n_layers\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_layers, ff\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mff\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m DLRUConfig(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, config)\n\u001b[0;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DLRUConfig' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = DLRUConfig(\n",
    "    d_model=cfg.d_model, d_state=cfg.d_state, n_layers=cfg.n_layers, ff=cfg.ff\n",
    ")\n",
    "model = DLRUConfig(1, 3, config)\n",
    "model.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODES = []\n",
    "FIT_MEAN = []\n",
    "for modes in range(cfg.d_state, 0, -1):\n",
    "\n",
    "    model_reduced = copy.deepcopy(model)\n",
    "\n",
    "    for block in model_reduced.blocks:\n",
    "\n",
    "        # reduction pipeline\n",
    "        ss_params = block.lru.ss_params()\n",
    "        ss_params = [param.detach().numpy() for param in ss_params]\n",
    "        lambdas, B, C, D = ss_params\n",
    "        lambdas_red, B_red, C_red, D_red = lru_reduction_pipeline(lambdas, B, C, D,  modes=modes, method=reduction_method)\n",
    "\n",
    "\n",
    "        params_red = [lambdas_red.astype(np.complex64), B_red.astype(np.complex64), C_red.astype(np.complex64), D_red.astype(np.float32)]\n",
    "        params_red = [torch.tensor(param_red) for param_red in params_red]\n",
    "        block.lru.replace_ss_params(*params_red)\n",
    "\n",
    "    ut = torch.tensor(scaler_u.transform(u_test)).unsqueeze(0).float()\n",
    "    with torch.no_grad():\n",
    "        #    y_test_hat = model(ut, mode=\"scan\").squeeze(0).to(\"cpu\").numpy()\n",
    "        y_test_hat = model_reduced(ut, mode=\"scan\").squeeze(0).to(\"cpu\").numpy()\n",
    "\n",
    "    y_test_hat = scaler_y.inverse_transform(y_test_hat)\n",
    "\n",
    "    fit = torchid.metrics.fit_index(y_test, y_test_hat).mean()\n",
    "    MODES.append(modes)\n",
    "    FIT_MEAN.append(fit)\n",
    "\n",
    "MODES = np.array(MODES)\n",
    "FIT_MEAN = np.array(FIT_MEAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT_THRESHOLD = 83.25865396027804*0.99 # 1% less than the worst\n",
    "FIT_THRESHOLD = FIT_MEAN[0] * 0.99\n",
    "MIN_ORDER = MODES[FIT_MEAN > FIT_THRESHOLD].min()\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(MODES, FIT_MEAN)\n",
    "ax.axhline(FIT_THRESHOLD, color=\"red\")\n",
    "ax.axvline(MIN_ORDER, color=\"black\")\n",
    "ax.invert_xaxis()\n",
    "ax.grid(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
